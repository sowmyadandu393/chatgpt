# -*- coding: utf-8 -*-
"""
amp_sand_dasboard_make,model_dynamic_b6_c6_ss with row-19 replication per-sheet

What this version does:
- Bulk copy (shift) is limited to SOURCE rows B12..B18 only. Row 19 is NOT bulk-copied.
- Apply B8 style to C19,D19,E19,F19,G19,H19 and B20,B21 (per sheet) BEFORE mirroring.
- Apply "Summary Details"!B19 style to all written cells with row <= 18.
- Force 0.00% number format for D,E,G,H for rows >= 21.
- Replicate SOURCE row 19 (B..H) into DEST rows starting at 22.
  **Counts are controlled PER SHEET** via ROW_REPEAT_COUNT_PER_SHEET.
- Mirror F:G:H across selection blocks (I:K, L:N, …) — styles/values flow automatically.
- Remove calcChain to avoid the Excel “We found a problem with some content” prompt.
"""

import io, csv, zipfile, boto3, re, os, shutil, time
from pathlib import Path
import xml.etree.ElementTree as ET

# ------------ S3 ------------
SRC_BUCKET    = "amp-caspex-sowmya"
SRC_KEY       = "dashboard_test/Updated ARA Reporting Mock Ups_make_model_one_ss.xlsx"

DST_IN_BUCKET = "amp-caspex-sowmya"
DST_IN_KEY    = "dashboard-output/updated_file.xlsx"

OUT_BUCKET    = "amp-caspex-sowmya"
OUT_KEY       = "dashboard-output/sanitized_debug_filled.xlsx"

CSV_BUCKET    = OUT_BUCKET
CSV_KEY       = "dashboard-output/mm_formulas_dump_with_style.csv"

# ------------ SHEETS / RANGE ---------------------
SHEETS = [
    "Top Make, Model Details - New",
    "Top Make, Model Details - Used",
]

SRC_START_COL_LETTER = "B"
SRC_START_ROW        = 12            # read from here in source
DST_START_ROW        = 15            # write here in destination (B15..)
ROW_OFFSET           = DST_START_ROW - SRC_START_ROW  # +3 shift

# Limit bulk dump: do NOT copy anything from source row >= 19 (we handle 19 via replication)
MAX_SRC_ROW_FOR_SHIFT = 18

# Mirroring config
SELECTION_COUNT    = 0               # supports 0..13 (0 means: NO MIRRORING)
MIRROR_START_ROW   = 14              # mirror F:G:H from row 14 (covers 14..19 too)

# ----------- NEW: per-sheet row replication counts -----------
ROW_REPEAT_COUNT_PER_SHEET = {
    "Top Make, Model Details - New": 11,   # example
    "Top Make, Model Details - Used": 6,  # example
}
DEFAULT_ROW_REPEAT_COUNT = 0

# Percent-format enforcement
PERCENT_TWO_DEC_COLS = {"D", "E", "G", "H"}
PERCENT_FROM_ROW     = 21            # apply 0.00% only from row 21+

# Style references
DATA_STYLE_REF_PER_SHEET = {
    "Top Make, Model Details - New":  "C8",
    "Top Make, Model Details - Used": "C8",
}
EMPTY_STYLE_SHEET = "Time to Purchase Details - New"
EMPTY_STYLE_CELL  = "D10"

# Apply Summary Details style up to (and including) row 18
SUMMARY_SHEET_NAME = "Summary Details"
SUMMARY_STYLE_REF  = "B19"
SUMMARY_STYLE_APPLY_UNTIL_ROW = 18  # inclusive

# ------------ Namespaces -------------------------
NS_MAIN  = "http://schemas.openxmlformats.org/spreadsheetml/2006/main"
NS_REL   = "http://schemas.openxmlformats.org/officeDocument/2006/relationships"
NS_MC    = "http://schemas.openxmlformats.org/markup-compatibility/2006"
NS_X14AC = "http://schemas.microsoft.com/office/spreadsheetml/2009/9/ac"
NS_XR    = "http://schemas.openxmlformats.org/spreadsheetml/2014/revision"
NS_XR2   = "http://schemas.openxmlformats.org/office/spreadsheetml/2015/revision2"
NS_XR3   = "http://schemas.openxmlformats.org/office/spreadsheetml/2016/revision3"

ET.register_namespace("", NS_MAIN)
ET.register_namespace("r", NS_REL)
ET.register_namespace("mc", NS_MC)
ET.register_namespace("x14ac", NS_X14AC)
ET.register_namespace("xr", NS_XR)
ET.register_namespace("xr2", NS_XR2)
ET.register_namespace("xr3", NS_XR3)

NS = "{%s}" % NS_MAIN
A1_RE = re.compile(r"^([A-Z]{1,3})(\d+)$")

# ------------- Zip helpers -----------------------
def unzip_bytes(data: bytes, out_dir: Path):
    if out_dir.exists():
        shutil.rmtree(out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)
    with zipfile.ZipFile(io.BytesIO(data)) as z:
        z.extractall(out_dir)

def rezip_dir(root: Path) -> bytes:
    MIN_DOS_TIME = 315532800  # 1980-01-01
    buf = io.BytesIO()
    with zipfile.ZipFile(buf, "w", compression=zipfile.ZIP_DEFLATED, allowZip64=True) as z:
        for base, _, files in os.walk(root):
            for f in sorted(files):
                ap = Path(base) / f
                rp = ap.relative_to(root).as_posix()
                zi = zipfile.ZipInfo(rp)
                try:
                    mtime = max(int(ap.stat().st_mtime), MIN_DOS_TIME)
                except Exception:
                    mtime = MIN_DOS_TIME
                zi.date_time = time.localtime(mtime)[:6]
                zi.compress_type = zipfile.ZIP_DEFLATED
                with open(ap, "rb") as fh:
                    z.writestr(zi, fh.read())
    buf.seek(0)
    return buf.getvalue()

def remove_calc_chain(root: Path):
    chain = root / "xl/calcChain.xml"
    if chain.exists():
        chain.unlink()
    rels = root / "xl/_rels/workbook.xml.rels"
    if rels.exists():
        t = ET.parse(rels); r = t.getroot(); changed = False
        for rel in list(r):
            if rel.attrib.get("Type","").endswith("/calcChain"):
                r.remove(rel); changed = True
        if changed:
            t.write(rels, encoding="utf-8", xml_declaration=True)

# ------------- Workbook helpers ------------------
def find_sheet_xml_by_name(root: Path, sheet_name: str) -> Path:
    wb = ET.parse(root / "xl/workbook.xml").getroot()
    rels_root = ET.parse(root / "xl/_rels/workbook.xml.rels").getroot()
    rid2target = {}
    for rel in rels_root:
        if rel.tag.endswith("Relationship"):
            rid2target[rel.attrib["Id"]] = rel.attrib["Target"].lstrip("/")
    for sh in wb.findall(f".//{NS}sheets/{NS}sheet"):
        if sh.attrib.get("name") == sheet_name:
            rid = sh.attrib[f"{{{NS_REL}}}id"]
            target = rid2target[rid]
            return (root / "xl" / target).resolve()
    raise FileNotFoundError(sheet_name)

def load_shared_strings(root: Path):
    sst_path = root / "xl/sharedStrings.xml"
    if not sst_path.exists():
        return []
    sst_root = ET.parse(sst_path).getroot()
    out = []
    for si in sst_root.findall(f".//{NS}si"):
        parts = []
        for t in si.findall(f".//{NS}t"):
            parts.append(t.text or "")
        out.append("".join(parts))
    return out

# ------------- Cell helpers ----------------------
def col_to_num(col: str) -> int:
    n = 0
    for ch in col.upper():
        n = n * 26 + (ord(ch) - 64)
    return n

def num_to_col(n: int) -> str:
    s = ""
    while n:
        n, r = divmod(n - 1, 26)
        s = chr(65 + r) + s
    return s

def get_row(sheet_root, rnum: int):
    return sheet_root.find(f".//{NS}sheetData/{NS}row[@r='{rnum}']")

def ensure_row(sheet_root, rnum: int):
    sheetData = sheet_root.find(f".//{NS}sheetData")
    if sheetData is None:
        sheetData = ET.SubElement(sheet_root, f"{NS}sheetData")
    row = sheetData.find(f"{NS}row[@r='{rnum}']")
    if row is None:
        row = ET.SubElement(sheetData, f"{NS}row", {"r": str(rnum)})
    return row

def find_cell(sheet_root, a1: str):
    m = A1_RE.match(a1)
    if not m: return None
    row = get_row(sheet_root, int(m.group(2)))
    if row is None: return None
    for c in row.findall(f"{NS}c"):
        if c.attrib.get("r") == a1:
            return c
    return None

def sort_row_cells(row):
    cells = row.findall(f"{NS}c")
    if not cells: return
    def key(c):
        m = A1_RE.match(c.attrib.get("r","A1"))
        return col_to_num(m.group(1)) if m else 0
    for c in cells: row.remove(c)
    for c in sorted(cells, key=key): row.append(c)

def update_row_spans(row):
    cells = row.findall(f"{NS}c")
    if not cells:
        row.attrib.pop("spans", None); return
    cols = []
    for c in cells:
        m = A1_RE.match(c.attrib.get("r","A1"))
        if m: cols.append(col_to_num(m.group(1)))
    if cols:
        row.attrib["spans"] = f"{min(cols)}:{max(cols)}"

def expand_dimension_to_include(sheet_root, col_letter: str, rownum: int):
    dim = sheet_root.find(f".//{NS}dimension")
    if dim is None:
        ET.SubElement(sheet_root, f"{NS}dimension", {"ref": f"A1:{col_letter}{rownum}"})
        return
    ref = dim.attrib.get("ref","A1:A1")
    end = ref.split(":")[-1]
    m_end = A1_RE.match(end)
    if not m_end:
        dim.attrib["ref"] = f"A1:{col_letter}{rownum}"
        return
    cur_col, cur_row = m_end.group(1), int(m_end.group(2))
    new_col_idx = max(col_to_num(cur_col), col_to_num(col_letter))
    new_row = max(cur_row, rownum)
    dim.attrib["ref"] = f"A1:{num_to_col(new_col_idx)}{new_row}"

# ------------- Source scan helpers ----------------
def cell_has_content(c):
    if c.find(f"{NS}f") is not None and (c.find(f"{NS}f").text or "") != "":
        return True
    if c.find(f"{NS}v") is not None and (c.find(f"{NS}v").text or "") != "":
        return True
    if c.find(f"{NS}is") is not None:
        t = c.find(f"{NS}is").find(f"{NS}t")
        if t is not None and (t.text or "") != "":
            return True
    return False

def max_row_col_from(sheet_root, start_col_idx: int, start_row: int):
    sd = sheet_root.find(f".//{NS}sheetData")
    if sd is None: return start_row, start_col_idx
    mr, mc = start_row, start_col_idx
    for row in sd.findall(f"{NS}row"):
        rnum = int(row.attrib.get("r","0"))
        if rnum < start_row: continue
        for c in row.findall(f"{NS}c"):
            a1 = c.attrib.get("r") or ""
            m = A1_RE.match(a1)
            if not m: continue
            ci = col_to_num(m.group(1))
            if ci < start_col_idx: continue
            if cell_has_content(c):
                mr, mc = max(mr, rnum), max(mc, ci)
    return mr, mc

def source_cell_kind_payload(sst, c_el):
    f_el = c_el.find(f"{NS}f")
    if f_el is not None and f_el.text:
        return ("formula", f_el.text)
    t = c_el.attrib.get("t")
    v = c_el.find(f"{NS}v")
    if (t is None or t == "") and v is not None and v.text is not None:
        return ("number", v.text)
    if t == "s" and v is not None and v.text is not None:
        try:
            idx = int(v.text)
            text = sst[idx] if 0 <= idx < len(sst) else ""
        except Exception:
            text = ""
        return ("inline", text)
    if t == "inlineStr":
        is_el = c_el.find(f"{NS}is"); t_el = is_el.find(f"{NS}t") if is_el is not None else None
        return ("inline", (t_el.text if t_el is not None else "") or "")
    return ("blank", "")

# ------------- Style helpers ---------------------
def get_style_idx_for_cell(sheet_root, a1: str):
    c = find_cell(sheet_root, a1)
    if c is not None and "s" in c.attrib:
        return c.attrib["s"]
    return None

def ensure_percent_2dec_style(styles_xml_path: Path, base_style_idx):
    """Ensure there's an xf with numFmtId 10 (0.00%). Return its index as string."""
    if not styles_xml_path.exists():
        return base_style_idx if base_style_idx is not None else "0"
    TT = lambda t: f"{{{NS_MAIN}}}{t}"
    tree = ET.parse(styles_xml_path); root = tree.getroot()
    cellXfs = root.find(TT("cellXfs"))
    if cellXfs is None or len(list(cellXfs)) == 0:
        return base_style_idx if base_style_idx is not None else "0"
    xfs = cellXfs.findall(TT("xf"))
    for i, xf in enumerate(xfs):
        if xf.get("numFmtId") == "10":   # 0.00%
            return str(i)
    try:
        base_idx = int(base_style_idx) if base_style_idx is not None else 0
    except:
        base_idx = 0
    base_idx = base_idx if 0 <= base_idx < len(xfs) else 0
    base = xfs[base_idx]
    new_xf = ET.Element(TT("xf"), base.attrib)
    new_xf.set("numFmtId", "10")
    new_xf.set("applyNumberFormat", "1")
    cellXfs.append(new_xf)
    try:
        cnt = int(cellXfs.get("count", str(len(xfs))))
    except:
        cnt = len(xfs)
    cellXfs.set("count", str(cnt + 1))
    tree.write(styles_xml_path, encoding="utf-8", xml_declaration=True)
    return str(len(xfs))

def a1_col_letter(a1: str) -> str:
    i = 0
    while i < len(a1) and a1[i].isalpha():
        i += 1
    return a1[:i] or "A"

def a1_row_num(a1: str) -> int:
    m = A1_RE.match(a1)
    return int(m.group(2)) if m else 0

# ------------- CSV dump with DEST shift ----------
def dump_source_to_csv(src_root_dir: Path, sheets: list, src_start_col_letter: str,
                       src_start_row: int, row_offset: int, max_src_row: int) -> bytes:
    """
    Dump only from src_start_row .. min(max_src_row, max_r_detected)
    so we never copy anything >= max_src_row+1 via the bulk path.
    """
    sst = load_shared_strings(src_root_dir)
    mem = io.StringIO()
    w = csv.writer(mem)
    w.writerow(["sheet","a1","kind","payload","style_tag"])

    start_ci = col_to_num(src_start_col_letter)

    for sheet in sheets:
        p = find_sheet_xml_by_name(src_root_dir, sheet)
        root = ET.parse(p).getroot()

        max_r_detected, max_c = max_row_col_from(root, start_ci, src_start_row)
        stop_r = min(max_r_detected, max_src_row)  # <= 18

        if stop_r < src_start_row:
            continue

        have = set()
        sd = root.find(f".//{NS}sheetData")
        if sd is not None:
            for row in sd.findall(f"{NS}row"):
                rn = int(row.attrib.get("r","0"))
                if rn < src_start_row or rn > stop_r: continue
                for c in row.findall(f"{NS}c"):
                    a1 = c.attrib.get("r") or ""
                    m = A1_RE.match(a1)
                    if not m: continue
                    ci = col_to_num(m.group(1))
                    if ci < start_ci: continue
                    if cell_has_content(c):
                        have.add(a1)

        for rn in range(src_start_row, stop_r + 1):
            dest_rn = rn + row_offset
            for ci in range(start_ci, max_c + 1):
                col_letter = num_to_col(ci)
                src_a1  = f"{col_letter}{rn}"
                dest_a1 = f"{col_letter}{dest_rn}"
                if src_a1 in have:
                    c = find_cell(root, src_a1)
                    kind, payload = source_cell_kind_payload(sst, c)
                    w.writerow([sheet, dest_a1, kind, (payload if payload is not None else ""), "data"])
                else:
                    w.writerow([sheet, dest_a1, "blank", "", "empty"])

    return mem.getvalue().encode("utf-8")

# ------------- Writers (apply) -------------------
def write_inline(target_root, a1, text, style_idx=None):
    m = A1_RE.match(a1); row = ensure_row(target_root, int(m.group(2)))
    old = find_cell(target_root, a1)
    if old is not None: row.remove(old)
    c = ET.SubElement(row, f"{NS}c", {"r": a1})
    if style_idx is not None: c.attrib["s"] = style_idx
    c.attrib["t"] = "inlineStr"
    is_el = ET.SubElement(c, f"{NS}is")
    ET.SubElement(is_el, f"{NS}t").text = text or ""
    sort_row_cells(row); update_row_spans(row)

def write_number(target_root, a1, num_text, style_idx=None):
    m = A1_RE.match(a1); row = ensure_row(target_root, int(m.group(2)))
    old = find_cell(target_root, a1)
    if old is not None: row.remove(old)
    c = ET.SubElement(row, f"{NS}c", {"r": a1})
    if style_idx is not None: c.attrib["s"] = style_idx
    ET.SubElement(c, f"{NS}v").text = str(num_text)
    c.attrib.pop("t", None)
    sort_row_cells(row); update_row_spans(row)

def write_formula(target_root, a1, formula_text, style_idx=None):
    if not formula_text.startswith("="):
        formula_text = "=" + formula_text
    m = A1_RE.match(a1); row = ensure_row(target_root, int(m.group(2)))
    old = find_cell(target_root, a1)
    if old is not None: row.remove(old)
    c = ET.SubElement(row, f"{NS}c", {"r": a1})
    if style_idx is not None: c.attrib["s"] = style_idx
    ET.SubElement(c, f"{NS}f").text = formula_text
    c.attrib.pop("t", None)
    sort_row_cells(row); update_row_spans(row)

def write_blank_with_style(target_root, a1, style_idx=None):
    m = A1_RE.match(a1); row = ensure_row(target_root, int(m.group(2)))
    old = find_cell(target_root, a1)
    if old is not None: row.remove(old)
    c = ET.SubElement(row, f"{NS}c", {"r": a1})
    if style_idx is not None: c.attrib["s"] = style_idx
    c.attrib["t"] = "inlineStr"
    is_el = ET.SubElement(c, f"{NS}is")
    ET.SubElement(is_el, f"{NS}t").text = ""
    sort_row_cells(row); update_row_spans(row)

# ------------- Apply CSV to destination ----------
def apply_csv_to_destination(dst_root_dir: Path, csv_bytes: bytes):
    # Base styles for "empty" and per-sheet "data"
    p_empty = find_sheet_xml_by_name(dst_root_dir, EMPTY_STYLE_SHEET)
    r_empty = ET.parse(p_empty).getroot()
    empty_style_idx = get_style_idx_for_cell(r_empty, EMPTY_STYLE_CELL)

    data_style_idx = {}
    for sheet in SHEETS:
        p = find_sheet_xml_by_name(dst_root_dir, sheet)
        r = ET.parse(p).getroot()
        data_style_idx[sheet] = get_style_idx_for_cell(r, DATA_STYLE_REF_PER_SHEET.get(sheet, "C8"))

    # Summary Details B19 style once
    p_sum = find_sheet_xml_by_name(dst_root_dir, SUMMARY_SHEET_NAME)
    r_sum = ET.parse(p_sum).getroot()
    summary_b19_style = get_style_idx_for_cell(r_sum, SUMMARY_STYLE_REF)

    styles_xml = dst_root_dir / "xl" / "styles.xml"
    base_any = summary_b19_style or next((v for v in data_style_idx.values() if v is not None), "0")
    percent_2dec_sidx = ensure_percent_2dec_style(styles_xml, base_any)

    mem = io.StringIO(csv_bytes.decode("utf-8"))
    rdr = csv.DictReader(mem)

    cache = {}

    for row in rdr:
        sheet = row["sheet"]; a1 = row["a1"]; kind = row["kind"]
        payload = row["payload"]; style_tag = row.get("style_tag","data")

        p = find_sheet_xml_by_name(dst_root_dir, sheet)
        k = p.as_posix()
        if k not in cache:
            t = ET.parse(p); cache[k] = (t, t.getroot(), p)
        t, root, path = cache[k]

        rn = a1_row_num(a1)
        colL = a1_col_letter(a1)

        # Decide style index:
        if rn <= SUMMARY_STYLE_APPLY_UNTIL_ROW:
            sidx = summary_b19_style
        else:
            sidx = data_style_idx.get(sheet) if style_tag == "data" else empty_style_idx
            if (colL in PERCENT_TWO_DEC_COLS) and (rn >= PERCENT_FROM_ROW):
                sidx = percent_2dec_sidx

        # write the cell
        if kind == "formula":
            write_formula(root, a1, payload, style_idx=sidx)
        elif kind == "number":
            write_number(root, a1, payload, style_idx=sidx)
        elif kind == "inline":
            write_inline(root, a1, payload, style_idx=sidx)
        else:
            write_blank_with_style(root, a1, style_idx=sidx)

    # finalize dimension and write sheets
    for k, (t, root, path) in cache.items():
        max_col = "A"; max_row = 1
        sd = root.find(f".//{NS}sheetData")
        if sd is not None:
            for row in sd.findall(f"{NS}row"):
                rn = int(row.attrib.get("r","1"))
                if rn > max_row: max_row = rn
                for c in row.findall(f"{NS}c"):
                    a1 = c.attrib.get("r") or "A1"
                    m = A1_RE.match(a1)
                    if m:
                        col = m.group(1)
                        if col_to_num(col) > col_to_num(max_col): max_col = col
        expand_dimension_to_include(root, max_col, max_row)
        t.write(path, encoding="utf-8", xml_declaration=True)

# ------------- Header style copier ---------------
def copy_style(sheet_root, src_a1: str, dst_a1_list: list):
    """Copy only the style index from src to each dst (no value change)."""
    src = find_cell(sheet_root, src_a1)
    if src is None: return
    sidx = src.attrib.get("s")
    if sidx is None: return
    for a1 in dst_a1_list:
        row = ensure_row(sheet_root, int(A1_RE.match(a1).group(2)))
        c = find_cell(sheet_root, a1)
        if c is None:
            c = ET.SubElement(row, f"{NS}c", {"r": a1})
        c.attrib["s"] = sidx
        sort_row_cells(row); update_row_spans(row)

def apply_header_style_adjustments(dst_root_dir: Path):
    """
    Apply B8 style to [C19,D19,E19,F19,G19,H19,B20,B21] on each make/model sheet.
    Done BEFORE mirroring so styles on F/G/H19 propagate to I/J/K… blocks.
    """
    targets = ["C19","D19","E19","F19","G19","H19","B20","B21"]
    for sheet in SHEETS:
        p = find_sheet_xml_by_name(dst_root_dir, sheet)
        t = ET.parse(p); root = t.getroot()
        copy_style(root, "B8", targets)
        t.write(p, encoding="utf-8", xml_declaration=True)

# ------------- MIRRORING (F:G:H -> destinations) -------------
def clone_cell_into(sheet_root, src_a1: str, dst_a1: str):
    src = find_cell(sheet_root, src_a1)
    m_dst = A1_RE.match(dst_a1)
    if src is None or not m_dst:
        return
    row = ensure_row(sheet_root, int(m_dst.group(2)))

    old = find_cell(sheet_root, dst_a1)
    if old is not None:
        row.remove(old)

    c = ET.SubElement(row, f"{NS}c", {"r": dst_a1})
    if "s" in src.attrib: c.attrib["s"] = src.attrib["s"]
    if "t" in src.attrib: c.attrib["t"] = src.attrib["t"]

    f_el = src.find(f"{NS}f")
    if f_el is not None and f_el.text:
        ET.SubElement(c, f"{NS}f").text = f_el.text
    v_el = src.find(f"{NS}v")
    if v_el is not None and v_el.text is not None:
        ET.SubElement(c, f"{NS}v").text = v_el.text
    is_el = src.find(f"{NS}is")
    if is_el is not None:
        is2 = ET.SubElement(c, f"{NS}is")
        for child in list(is_el):
            new_child = ET.SubElement(is2, child.tag)
            new_child.text = child.text

    sort_row_cells(row); update_row_spans(row)

def compute_block_starts(selection_count: int):
    """
    Always start copies at column I. For count N, return columns:
    I, L, O, ... (each block is 3 columns wide).
    """
    if selection_count <= 0:
        return []
    starts = []
    start_idx = col_to_num("I")
    for i in range(selection_count):
        starts.append(num_to_col(start_idx + 3*i))
    return starts

def mirror_sheet_fixed_blocks(sheet_root, start_row: int, selection_count: int):
    last_used = start_row
    sd = sheet_root.find(f".//{NS}sheetData")
    if sd is not None:
        for row in sd.findall(f"{NS}row"):
            rn = int(row.attrib.get("r","0"))
            if rn < start_row: continue
            for col in ("F","G","H"):
                if find_cell(sheet_root, f"{col}{rn}") is not None:
                    last_used = max(last_used, rn)

    dest_starts = compute_block_starts(selection_count)

    for rn in range(start_row, last_used + 1):
        src_cols = ["F","G","H"]
        for start_col in dest_starts:
            start_idx = col_to_num(start_col)
            for i, s_col in enumerate(src_cols):
                src_a1 = f"{s_col}{rn}"
                dst_col = num_to_col(start_idx + i)
                dst_a1 = f"{dst_col}{rn}"
                clone_cell_into(sheet_root, src_a1, dst_a1)

    if dest_starts:
        last_block_start = dest_starts[-1]
        end_col = num_to_col(col_to_num(last_block_start) + 2)
        expand_dimension_to_include(sheet_root, end_col, last_used)

# ------------- Replicate src row 19 -> dest row 22 (PER SHEET) -------------
def replicate_row19_to_dest_per_sheet(dst_root_dir: Path, src_root_dir: Path,
                                      per_sheet_counts: dict, default_count: int = 0):
    """
    For each SHEET:
      - Read SOURCE row 19, cols B..H (kind + payload)
      - In DEST, write those values to rows 22..(21+repeat_count_for_that_sheet)
        with normal 'data' style and percent enforcement for D/E/G/H (>= row 21)
    """
    sst = load_shared_strings(src_root_dir)
    src_row = 19
    dest_start_row = 22
    cols = [chr(c) for c in range(ord('B'), ord('H')+1)]  # B..H

    # Prepare base styles
    p_empty = find_sheet_xml_by_name(dst_root_dir, EMPTY_STYLE_SHEET)
    r_empty = ET.parse(p_empty).getroot()
    empty_style_idx = get_style_idx_for_cell(r_empty, EMPTY_STYLE_CELL)

    data_style_idx = {}
    for sheet in SHEETS:
        p_dst = find_sheet_xml_by_name(dst_root_dir, sheet)
        r_dst = ET.parse(p_dst).getroot()
        data_style_idx[sheet] = get_style_idx_for_cell(r_dst, DATA_STYLE_REF_PER_SHEET.get(sheet, "C8"))

    styles_xml = dst_root_dir / "xl" / "styles.xml"
    base_any = next((v for v in data_style_idx.values() if v is not None), "0")
    percent_2dec_sidx = ensure_percent_2dec_style(styles_xml, base_any)

    # For each sheet, read src B19..H19 then write to dest using its own repeat count
    for sheet in SHEETS:
        repeat_count = int(per_sheet_counts.get(sheet, default_count))
        if repeat_count <= 0:
            continue

        p_src = find_sheet_xml_by_name(src_root_dir, sheet)
        root_src = ET.parse(p_src).getroot()

        p_dst = find_sheet_xml_by_name(dst_root_dir, sheet)
        t_dst = ET.parse(p_dst); root_dst = t_dst.getroot()

        # collect source kinds/payloads once
        row_payloads = []
        for col in cols:
            c_el = find_cell(root_src, f"{col}{src_row}")
            if c_el is None:
                row_payloads.append(("blank", "")); continue
            kind, payload = source_cell_kind_payload(sst, c_el)
            row_payloads.append((kind, payload))

        # write to dest rows
        last_row_written = dest_start_row - 1
        for i in range(repeat_count):
            rn = dest_start_row + i
            for idx, col in enumerate(cols):
                kind, payload = row_payloads[idx]
                # Decide style
                sidx = data_style_idx.get(sheet) or empty_style_idx
                if (col in PERCENT_TWO_DEC_COLS) and (rn >= PERCENT_FROM_ROW):
                    sidx = percent_2dec_sidx

                a1 = f"{col}{rn}"
                if kind == "number":
                    write_number(root_dst, a1, payload, style_idx=sidx)
                elif kind == "inline":
                    write_inline(root_dst, a1, payload, style_idx=sidx)
                elif kind == "formula":
                    write_formula(root_dst, a1, payload, style_idx=sidx)
                else:
                    write_blank_with_style(root_dst, a1, style_idx=sidx)

            last_row_written = rn

        # ensure dimension
        expand_dimension_to_include(root_dst, cols[-1], last_row_written)
        t_dst.write(p_dst, encoding="utf-8", xml_declaration=True)

# ------------------ MAIN ------------------------
def main():
    s3 = boto3.client("s3")

    buf_src = io.BytesIO(); s3.download_fileobj(SRC_BUCKET, SRC_KEY, buf_src); buf_src.seek(0)
    buf_dst = io.BytesIO(); s3.download_fileobj(DST_IN_BUCKET, DST_IN_KEY, buf_dst); buf_dst.seek(0)

    src_dir = Path("/tmp/xlsx_src_dump");  unzip_bytes(buf_src.getvalue(), src_dir)
    dst_dir = Path("/tmp/xlsx_dst_apply"); unzip_bytes(buf_dst.getvalue(), dst_dir)

    # Remove calcChain up front
    remove_calc_chain(dst_dir)

    # Bulk dump ONLY up to source row 18 (so nothing at/after 19 is bulk-copied)
    csv_bytes = dump_source_to_csv(
        src_dir, SHEETS, SRC_START_COL_LETTER, SRC_START_ROW, ROW_OFFSET, MAX_SRC_ROW_FOR_SHIFT
    )
    # (Optional) keep a diagnostics CSV in S3
    s3.upload_fileobj(io.BytesIO(csv_bytes), CSV_BUCKET, CSV_KEY)
    print(f"CSV written: s3://{CSV_BUCKET}/{CSV_KEY}  bytes={len(csv_bytes)}")

    # Apply main values/styles to DEST (<= row 18 + shift)
    apply_csv_to_destination(dst_dir, csv_bytes)

    # Apply B8 style to C19..H19 and B20,B21 BEFORE mirroring
    apply_header_style_adjustments(dst_dir)

    # Replicate ONLY SOURCE row 19 (B..H) into DEST rows 22.. per sheet count
    replicate_row19_to_dest_per_sheet(
        dst_root_dir=dst_dir,
        src_root_dir=src_dir,
        per_sheet_counts=ROW_REPEAT_COUNT_PER_SHEET,
        default_count=DEFAULT_ROW_REPEAT_COUNT
    )

    # Mirror F:G:H from row 14 across selection blocks (styles/values flow)
    if SELECTION_COUNT > 0:
        for sheet in SHEETS:
            p = find_sheet_xml_by_name(dst_dir, sheet)
            t = ET.parse(p); root = t.getroot()
            mirror_sheet_fixed_blocks(root, MIRROR_START_ROW, SELECTION_COUNT)
            t.write(p, encoding="utf-8", xml_declaration=True)
    else:
        print("SELECTION_COUNT=0 → mirroring skipped")

    out_bytes = rezip_dir(dst_dir)
    s3.upload_fileobj(io.BytesIO(out_bytes), OUT_BUCKET, OUT_KEY)
    print(f"UPDATED workbook → s3://{OUT_BUCKET}/{OUT_KEY}")

if __name__ == "__main__":
    main()
